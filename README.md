# ğŸš€ High Availability Slurm Cluster using Pacemaker, Corosync & DRBD

## ğŸ“Œ Project Overview
This project implements a **Highly Available (HA) Slurm Workload Manager cluster** using:

- Pacemaker (Cluster Resource Manager)
- Corosync (Cluster Communication Layer)
- DRBD (Block-Level Data Replication)
- Virtual IP Failover
- MariaDB for Slurm Accounting
- Shared Slurm State Storage

The objective is to provide **automatic failover of Slurm Controller services** with minimal downtime while ensuring data consistency across controller nodes.

---

## ğŸ¯ Objectives

- Achieve High Availability for Slurm Controller
- Prevent Single Point of Failure
- Automatic Service Failover
- Replicated Slurm State Data
- Seamless Job Scheduling Continuity
- Fast Recovery during Node Failure

---

## ğŸ§± Architecture
Users
 â†“
WireGuard VPN
 â†“
OnDemand Web Portal
 â†“
Login Node
 â†“
Slurm VIP
 â†“
Active Controller (Pacemaker)
 â†“
DRBD Replicated Storage
 â†“
Compute Nodes

Monitoring Layer:

Prometheus â† exporters on all nodes
     â†“
Alertmanager
     â†“
Grafana Dashboards


---

### ğŸ”— Core Components

| Component | Purpose |
|-----------|---------|
| Corosync | Cluster Communication |
| Pacemaker | Resource Management |
| DRBD | Block Storage Replication |
| Virtual IP | Floating Controller Access |
| Slurmctld | Scheduler Controller |
| Slurmdbd | Accounting Database |
| MariaDB | Job Accounting Storage |

---


## ğŸ§© Key Features

âœ… Automatic Failover  
âœ… Controller Redundancy  
âœ… Data Replication  
âœ… Virtual IP Switching  
âœ… DRBD Synchronous Mode  
âœ… Pacemaker Resource Groups  
âœ… Service Ordering Constraints  

---
## âš™ï¸ Cluster Resource Flow

Pacemaker controls:

- DRBD Promotion/Demotion
- Filesystem Mount
- Database Service
- Slurm Services
- VIP Movement

---
3ï¸âƒ£ Configure Corosync Cluster

apt install pacemaker corosync pcs drbd-utils mariadb-server slurm-wlm

pcs cluster auth MasterNode PassiveMaster
pcs cluster setup SlurmHA MasterNode PassiveMaster
pcs cluster start --all

4ï¸âƒ£ Configure DRBD
Create resource:

/etc/drbd.d/slurm_data.res
Initialize:

drbdadm create-md slurm_data
drbdadm up slurm_data
Promote Primary:

drbdadm primary --force slurm_data

5ï¸âƒ£ Filesystem Setup
mkfs.ext4 /dev/drbd0
mount /dev/drbd0 /var/spool/slurm

6ï¸âƒ£ Create Pacemaker Resources
pcs resource create slurm_data_res ocf:linbit:drbd ...
pcs resource create slurm_fs Filesystem ...
pcs resource create mariadb systemd:mariadb
pcs resource create slurmdbd_res systemd:slurmdbd
pcs resource create slurm_ctld_res systemd:slurmctld
pcs resource create virtual_ip ocf:heartbeat:IPaddr2 ...

7ï¸âƒ£ Resource Group Example
DRBD
 â†’ Filesystem
   â†’ MariaDB
     â†’ SlurmDBD
       â†’ SlurmCTLD
         â†’ VIP

ğŸ”„ Failover Testing
Move Resources
pcs node standby PassiveMaster
Check Cluster
pcs status
Slurm Health
scontrol ping
sinfo

ğŸ“Š DRBD Sync Monitoring
cat /proc/drbd
watch -n1 drbdadm status

Output:

Primary/Secondary
SyncSource / SyncTarget
UpToDate/Inconsistent

---

## ğŸš¨ Common Issues Faced


---

## ğŸ“ˆ Project Outcomes

Fully functional HA Slurm cluster

Successful automatic failover

Replicated scheduler state

Stable cluster communication

Production-grade HPC control plane

---

## ğŸ§ª Validation

Controller Failover Successful

DRBD Replication Verified

Job Scheduling Survived Node Failure

VIP Migration Confirmed

Resource Ordering Enforced
---
